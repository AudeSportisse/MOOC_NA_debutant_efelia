{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WzoIMia78pjT"
   },
   "source": [
    "# Travaux pratiques 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iK7Ik2raUFQ1"
   },
   "source": [
    "Ce dernier TP est décomposé en deux parties. Dans la première partie, vous allez expliquer la variable indiquant le maximum d'ozone en fonction des températures. Dans la seconde partie, vous allez prédire le maximum d'ozone pour une nouvelle ville (en fonction de ces températures). Dans le premier cas, l'objectif est d'estimer des paramètres d'intérêt et vous avez accès au maximum d'ozone. Dans le second cas, l'objectif est de prédire le maximum d'ozone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BtFs9vARVF6D"
   },
   "source": [
    "# Chargement des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6aCD5wXqVaGk",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(missMDA)  # Inclut le dataset ozone\n",
    "library(VIM)  # Pour la visualisation de valeurs manquantes\n",
    "library(mice)  # Pour l'imputation multiple\n",
    "library(misaem)  # Pour le modèle linéaire avec valeurs manquantes\n",
    "library(parameters)  # Pour agréger les coefficients de l'imputation multiple\n",
    "library(caret)  # La boîte à outils de machine learning\n",
    "library(e1071)  # Pour les SVM\n",
    "library(xgboost)  # Pour le gradient boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0VAJzWvVJ4U"
   },
   "source": [
    "# Chargement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YfGb5Rv4VHnu"
   },
   "source": [
    "Dans tout ce TP, vous allez considérez les 4 premières variables du jeu de données `ozone` que vous avez découvert au TP1.\n",
    "\n",
    "La variable d'intérêt est le maximum d'ozone (`maxO3`) et les variables descriptives sont les températures à 9h, 12h et 15h (`T9`, `T12` et `T15`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4z5oaD_zVWHS",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "data(ozone) # chargement des données\n",
    "ozone <- ozone[, 1:4] # sélection des 4 premières variables (colonnes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YQHCvgahVjK1",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "head(ozone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpKT82QsWY6k"
   },
   "source": [
    "Comme vous le voyez ci-dessus, la variable `maxO3` contient des valeurs manquantes. C'est un cas en dehors du domaine de compétences développées dans ce MOOC. Dans la suite, nous ne considérons que les villes pour lesquelles le maximum d'ozone est observé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1FPAPIY3XrSn",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "ozone <- ozone[, 1:4]\n",
    "ozone <- ozone[-which(is.na(ozone$maxO3)), ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ytazPcm2Xyvy"
   },
   "source": [
    "On vérifie qu'il n'y a plus aucune valeur manquante pour `maxO3` en utilisant la librairie `VIM` et le code suivant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cVfMVoqyX8mc",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "a <- aggr(ozone, plot = FALSE)\n",
    "par(bg = \"white\") # définit le fond en blanc\n",
    "plot(a, numbers = TRUE, prop = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gT71gbgd8toX"
   },
   "source": [
    "# Estimation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IoslTYuHZFsz"
   },
   "source": [
    "Le but est de trouver les paramètres $\\beta_0$, $\\beta_1$, $\\beta_2$ et $\\beta_3$, qui expliquent la variable `maxO3` en fonction des variables de température `T9`, `T12` et `T15`, c'est-à-dire tels que:\n",
    "$$\\mathrm{maxO3}=\\beta_0+\\beta_1\\mathrm{T9}+\\beta_2\\mathrm{T12}+\\beta_3\\mathrm{T15}+\\textrm{bruit gaussien},$$\n",
    "où le $\\textrm{bruit gaussien}$ est un terme modélisant le bruit contenu dans les données, c'est une variable aléatoire qui suit une distribution Gaussienne.\n",
    "\n",
    "Vous allez voir quatre méthodes qui permettent de gérer les valeurs manquantes :\n",
    "* la suppression des lignes incomplètes,\n",
    "* l'algorithme EM,\n",
    "* l'imputation par la moyenne,\n",
    "* imputation multiple (question 4)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MAbPxrWZgWTE"
   },
   "source": [
    "## Question 1 : suppression des lignes incomplètes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bgTCb5qhgj95"
   },
   "source": [
    "Le code suivant permet d'estimer les paramètres, en supprimant les lignes qui contiennent des valeurs manquantes (lignes incomplètes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XKrB17bPgU3b",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "regression.complete.cases = lm(maxO3 ~ T9 + T12 + T15, data = ozone)\n",
    "regression.complete.cases$na.action # affichage des indices des lignes supprimées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pEFVe8iPhOxI"
   },
   "source": [
    "Les valeurs estimées des paramètres de la régression linéaire sont affichées ci-dessous. L'estimation pour `(Intercept)` correspond à $\\beta_0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JbdCjZAUg9GK",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "coef(regression.complete.cases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RFrbuq2t6k9C"
   },
   "source": [
    "On peut afficher les intervalles de confiance à 95% pour les coefficients estimés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1pEXZLY16ld5",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "confidence.complete.cases <- confint(regression.complete.cases)\n",
    "confidence.complete.cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HibowXhvhels"
   },
   "source": [
    "Pourquoi cette stratégie n'est-elle pas adaptée ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "srD83mCEhilw",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oiw7I5lFhlLc"
   },
   "source": [
    "Si les lignes incomplètes sont supprimées, il y a beaucoup d'information perdue. Au total, on garde 65 points sur 99 (presque 1/3 de supprimés). Le nombre de lignes complètes peut se lire sur le graphique de droite dans le chargement des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-S9Gwa1tieGU",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "dim(ozone)[1] # nombre de lignes total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWIqcGNIkvf7"
   },
   "source": [
    "## Question 2 : algorithme EM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCvQQAcxGnyB"
   },
   "source": [
    "Le code suivant utilise la librairie `misaem` qui permet d'estimer les coefficients $\\beta_0$, $\\beta_1$, $\\beta_2$ et $\\beta_3$ de la régression linéaire en utilisant l'algorithme Espérance-Maximisation (EM), sans supprimer les lignes incomplètes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vgMxRjSXIBHv",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "regression.em <- miss.lm(maxO3 ~ T9 + T12 + T15, data = ozone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mHnYbXk5Il2O"
   },
   "source": [
    "Les valeurs estimées des coefficients de la régression linéaire sont affichées ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TVfDwvv3IlRf",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "coef(regression.em)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3KdJIzHXJ498"
   },
   "source": [
    "Est-ce que les résultats sont semblables à ceux obtenus en question 1? Commentez."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddd8fX056r0w",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "81SuhZ2K6tLW"
   },
   "source": [
    "Les coefficients ont le même signe que lorsqu'ils sont estimés en supprimant les lignes incomplètes. Ils n'ont par contre pas les mêmes valeurs. Les coefficients obtenus précédemment sont sûrement biaisés, les lignes contenant des valeurs manquantes ayant été supprimées.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O3Io5plRWkUE"
   },
   "source": [
    "## Question 3 : imputation par la moyenne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TN5qf7J2Wuv3"
   },
   "source": [
    "Comparez ces résultats à une autre stratégie pour l'estimation en présence de valeurs manquantes, qui consiste à imputer par la moyenne puis appliquer une régression linéaire sur le jeu de données imputé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0q97v4FnXKPC",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "impute.mean <- function(data) { #fonction d'imputation par la moyenne\n",
    "  data.imputed <- data\n",
    "  for (j in 1:dim(data)[2]) {\n",
    "    data.imputed[which(is.na(data[, j])), j] <- mean(data[, j], na.rm = TRUE)\n",
    "  }\n",
    "  return(data.imputed)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "59qhzizSXNfQ",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "ozone.mean <- impute.mean(ozone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jouJ4ecXXN9z",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "regression.imp.mean <- lm(maxO3 ~ T9 + T12 + T15, data = ozone.mean)\n",
    "coef(regression.imp.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EjMXsTCwXzSL",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a5LxQiiHX1Ox"
   },
   "source": [
    "Pour le coefficient de la variable `T9`, le signe n'est pas le même. L'interprétation des résultats est donc assez différente. Dans le module et TP1, on a vu que l'imputation par la moyenne déforme la distribution du jeu de données. La stratégie d'imputation par la moyenne puis régression donne des résultats biaisés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P8nI4h4vk01G"
   },
   "source": [
    "## Question 4 : imputation multiple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lMjzou1-k8p-"
   },
   "source": [
    "Dans l'estimation des coefficients, l'incertitude due à la présence de valeurs manquantes n'est pas reflétée. Vous allez maintenant utiliser la librairie `mice` qui permet d'obtenir plusieurs jeux de données imputés, sur lesquels une régression linéaire est ensuite appliquée. Cette méthode permet d'obtenir des intervalles de confiance pour les coefficients estimés. Elle est appelée imputation multiple, même si c'est en fait aussi une méthode d'estimation ! Ici, contrairement à la librairie `misaem`, il y a une étape d'imputation et une étape d'estimation des coefficients (régression linéaire sur les jeux de données imputés).  \n",
    "\n",
    "La ligne de code suivante permet d'obtenir $m$ jeux de données imputés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cpo6g0Qk7z-U",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "mult.imp <- mice(ozone, m = 20, print = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KAwtJNEd7JhD"
   },
   "source": [
    "On applique ensuite la régression linéaire sur tous les jeux de données imputés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wH-GK9st7KEm",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "fit <- with(mult.imp, lm(maxO3 ~ T9 + T12 + T15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HVx6eBnp7L8S"
   },
   "source": [
    "On peut afficher les deux premiers jeux de données imputés, et leurs régressions linéaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vct3djkA7OvP",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "complete.dataset.1 <- complete(mult.imp, 1) # jeu de données imputé 1\n",
    "head(complete.dataset.1, 10)\n",
    "\n",
    "coef(fit$analyses[[1]]) # analyse du jeu de donnée imputé 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q5n5vTtJ7S0u",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "complete.dataset.2 <- complete(mult.imp, 2) # jeu de données imputé 2\n",
    "head(complete.dataset.2, 10)\n",
    "\n",
    "coef(fit$analyses[[2]]) # analyse du jeu de données imputé 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qb2e1HjVKIYd"
   },
   "source": [
    "### Question 4a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A2SvgRus7N7s"
   },
   "source": [
    "Que remarquez-vous?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "poRONxWW7kSb",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BaE6nCX-7loV"
   },
   "source": [
    "Les deux premiers jeux de données imputés obtenus avec `mice` ont bien des valeurs prédites différentes pour les valeurs manquantes, et les estimations des coefficients sont différentes.\n",
    "\n",
    "Un exemple de valeur prédite différente est donné ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6zEiD-6u7YOu",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "paste(\"Valeur prédite dans le jeu de données imputé 1:\", complete.dataset.1[which(is.na(ozone$T9[1:10])), 2])\n",
    "\n",
    "paste(\"Valeur prédite dans le jeu de données imputé 2:\", complete.dataset.2[which(is.na(ozone$T9[1:10])), 2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQnvxAdN9BFk"
   },
   "source": [
    "### Question 4b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uv636AOn9DSP"
   },
   "source": [
    "Le code suivant permet d'obtenir les coefficients estimés aggrégés sur les $m=20$ jeux de données imputés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9mgsaOiO9O5C",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "res.mult <- model_parameters(fit)\n",
    "\n",
    "res.mult$Coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yz1lVEdc9Hm4"
   },
   "source": [
    "Pour obtenir des intervalles de confiance à 95% pour chaque coefficient, on applique le code suivant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dQxP64QV97gg",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "confidence.mult <- data.frame(as.numeric(res.mult$CI_low),\n",
    "                             as.numeric(res.mult$CI_high),\n",
    "                             row.names = res.mult$Parameter)\n",
    "colnames(confidence.mult) <- c(\"2.5%\", \"97.5%\")\n",
    "\n",
    "confidence.mult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8FMPy7Bv93eG"
   },
   "source": [
    "Comparez les résultats avec ceux obtenus précédemment, notamment ceux de la question 1 en supprimant les lignes incomplètes, pour les intervalles de confiance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idfeWJH2-1bp",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AEpkVkgnbUBL"
   },
   "source": [
    "Les valeurs des coefficients sont différentes, mais restent de même signe que ceux obtenus en question 1 (suppression des lignes incomplètes) et question 2 (algorithme EM).\n",
    "Pour les intervalles de confiance, on peut remarquer que leur longueur est plus grande lorsque les lignes incomplètes sont supprimées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u53Njm9tcDsQ",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Longueur des intervalles de confiance lorsque les lignes incomplètes sont supprimées\n",
    "length.confidence.complete.cases <- confidence.complete.cases[ ,2]-confidence.complete.cases[ ,1]\n",
    "length.confidence.complete.cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fE6IGChVcYvz",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Longueur des intervalles de confiance lorsque mice est utilisée\n",
    "length.confidence.mult <- confidence.mult[ ,2]-confidence.mult[ ,1]\n",
    "length.confidence.mult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWaiwg2ES00r"
   },
   "source": [
    "# Exercice 2 : prédiction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3sQs55hXvtN"
   },
   "source": [
    "Dans la première partie, nous avons vu comment estimer les paramètres d'une régression linéaire, modélisant la variable d'intérêt $y=$ `maxO3` en fonction des variables explicatives $X=$ `[T9, T12, T15]`, même si celles-ci avaient des valeurs manquantes. Rappelons le modèle que nous avons utilisé :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ap3LHqZkfApV",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "summary(regression.em)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UNQGvCu1fCSz"
   },
   "source": [
    "Nous nous sommes appuyés sur un jeu de données d'entraînement $(y_{train},~X_{train})$, construit lors d'une étude réalisée de juin à septembre 2001. Affichons à nouveau ses premières lignes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MPqxfS_GXvWK",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "print(head(ozone, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JXxoBD6hYalZ"
   },
   "source": [
    "## Question 1\n",
    "\n",
    "Imaginons maintenant que nous recevions un nouveau cas $X_{new}$ où $y$ est inconnue, et que nous souhaitions déterminer sa valeur la plus probable.\n",
    "\n",
    "Concrètement, on se place à une date ultérieure, le 1/07/2025, on mesure une température de 15.1°C à 9h, 16.8°C à 12h, et 19.7°C à 15h, et on souhaite déterminer la valeur maximale d'ozone sur la journée à partir de ces seules températures.\n",
    "\n",
    "C'est ce qu'on appelle la **prédiction**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MORruMlTfUu6",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "X.new <- data.frame(T9 = 15.1, T12 = 16.8, T15 = 19.7, row.names = '20250701')\n",
    "print(X.new)\n",
    "print(predict(regression.em, X.new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJ3AfH2L9hjK"
   },
   "source": [
    "Pourquoi rencontrerait-on une telle situation en pratique, avec le jeu de données `ozone` ? Donnez un exemple de scénario.\n",
    "\n",
    "Ensuite, dans votre domaine, trouvez un autre exemple de scénario impliquant de la prédiction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RueUgT8E9yVF",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQDhF7PufYEB"
   },
   "source": [
    "Dans notre cas du jeu de données `ozone`, on peut imaginer que la variable d'intérêt `maxO3` est technique ou chère à mesurer et qu'on n'en avait la possibilité que dans le cadre de l'étude de 2001, et on aimerait donc pouvoir la prédire au quotidien à partir des mesures de température uniquement, puisqu'elles sont faciles à réaliser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gUzA_qNnG06D"
   },
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQ4WWCgJ-KRH"
   },
   "source": [
    "\n",
    "\n",
    "Une autre difficulté s'ajoute dans notre cas. En général, si les nouvelles données sont récoltées dans les mêmes conditions que le jeu d'entraînement, il y a de fortes chances qu'il y ait aussi des valeurs manquantes dans $X_{new}$. Il faut donc le prendre en compte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oGyPlv2MaOqJ",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "X.new.na <- data.frame(T9 = 15.1, T12 = NA, T15 = 19.7, row.names = '20250701')\n",
    "print(X.new.na)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYjz8m3QHuoo"
   },
   "source": [
    "La première approche \"naïve\" est d'essayer de prédire directement avec le modèle qu'on a entraîné sur la nouvelle donnée..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BrExhgv5Hz-k",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "predict(regression.em, X.new.na)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LqV350eVImQB"
   },
   "source": [
    "Cela fonctionne-t-il ? Est-ce surprenant ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1r8-iRh_JO3a",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "73Kn-U_xH-nF"
   },
   "source": [
    "Cela fonctionne ! Alors pourquoi aller plus loin ?\n",
    "\n",
    "En réalité cette méthode du package `misaem` est loin d'être naïve, elle cache un algorithme complexe, qui examine toutes les combinaisons possibles de variables dans le modèle (et repose sur des hypothèses assez restrictives). Quand on a beaucoup de variables et beaucoup de prédictions à réaliser, le temps de calcul peut exploser. De plus, elle suppose que les valeurs manquantes n'ont pas d'influence particulière sur la réponse $y$, ce qui peut être faux."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LAe6LvBEHkQT"
   },
   "source": [
    "## Question 3 : approche en deux étapes avec l'imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DR7r-cW_a6Wp"
   },
   "source": [
    "Une alternative simple qui fonctionne avec n'importe quel modèle de machine learning, et qui est très souvent remarquablement efficace en prédiction, est **l'imputation par la moyenne** (ou la médiane, ça n'a pas d'importance dans ce cas).\n",
    "\n",
    "Implémentons-la à l'aide de la fonction `preProcess` du package `caret`, la boîte à outils de machine learning (qui ne supporte que la médiane).\n",
    "\n",
    "**Note importante :** pour utiliser cette méthode, il faut calculer les médianes **sur le jeu d'entraînement**, et imputer à la fois le jeu d'entraînement et les nouvelles données par ces mêmes médianes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "khUVah0TLk87"
   },
   "source": [
    "Dans la cellule suivante, commentez chaque ligne en expliquant ce qu'elle fait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HsK5rjbnK5iT",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "preproc <- preProcess(ozone[c(\"T9\", \"T12\", \"T15\")], method = \"medianImpute\")  # ???\n",
    "print(preproc$median)  # ???\n",
    "\n",
    "ozone.imputed <- predict(preproc, newdata = ozone)  # ???\n",
    "print(head(ozone.imputed))  # ???\n",
    "\n",
    "model <- miss.lm(maxO3 ~ ., data = ozone.imputed)  # ???\n",
    "print(summary(model))  # ???\n",
    "\n",
    "X.new.imputed <- predict(preproc, newdata = X.new.na)  # ???\n",
    "print(X.new.imputed)  # ???\n",
    "\n",
    "predictions <- predict(model, newdata = X.new.imputed)  # ???\n",
    "print(predictions)  # ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySkP9POZK8JS",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZJYvP4GqMZaA",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "preproc <- preProcess(ozone[c(\"T9\", \"T12\", \"T15\")], method = \"medianImpute\")  # Calcul des médianes des colonnes du jeu d'entraînement\n",
    "print(preproc$median)  # Affichage des médianes calculées\n",
    "\n",
    "ozone.imputed <- predict(preproc, newdata = ozone)  # Imputation du jeu d'entraînement avec les médianes précalculées\n",
    "print(head(ozone.imputed))  # Affichage des premières lignes du jeu de données imputé\n",
    "\n",
    "model <- miss.lm(maxO3 ~ ., data = ozone.imputed)  # Entraînement du modèle linéaire sur le jeu imputé\n",
    "print(summary(model))  # Affichage des paramètres du modèle\n",
    "\n",
    "X.new.imputed <- predict(preproc, newdata = X.new.na)  # Imputation des nouvelles données par les médianes précalculées\n",
    "print(X.new.imputed)  # Affichage des nouvelles données imputées\n",
    "\n",
    "prediction <- predict(model, newdata = X.new.imputed)  # Prédiction sur les nouvelles données imputées\n",
    "print(prediction)  # Affichage de la prédiction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RKK6Fqnh-QNT"
   },
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fYRn-toI-cgv"
   },
   "source": [
    "Le modèle linéaire a l'avantage de permettre d'interpréter complètement la relation entre $y$ et $X$, mais quelles sont ses limites ? Connaissez-vous d'autres modèles de *machine learning* et leurs avantages ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFuvjqP7-x7-",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mpXM1MTS2vEO"
   },
   "source": [
    "Le modèle linéaire n'est pas toujours le plus juste, car il ne modélise que des effets linéaires. En fait il est possible d'ajouter des effets combinés ou non linéaires, mais il faut les renseigner à la main, le modèle ne peut pas les deviner automatiquement. Par exemple, dans le modèle suivant :\n",
    "\n",
    "$$\\mathrm{maxO3}=\\beta_0+\\beta_1\\times\\mathrm{T9}+\\beta_2\\times\\mathrm{T12}+\\beta_3\\times\\mathrm{T15} +\\beta_4\\times\\left(T12-T9\\right)^2 +\\textrm{bruit gaussien},$$\n",
    "\n",
    "on a ajouté à la main un effet quadratique de la variation de température entre 9h et 12h, mais ça reste un modèle linéaire avec cinq paramètres, $\\beta_0, \\beta_1, \\beta_2, \\beta_3, \\beta_4$.\n",
    "\n",
    "\n",
    "Pour capturer automatiquement des effets combinés ou non linéaires, d'autres modèles existent, comme la machine à vecteurs de support (*Support Vector Machine, SVM*) ou les modèles à base d'arbres de décision comme le gradient boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eZNLq_BjLYvz"
   },
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OwHoEtiHLw1W"
   },
   "source": [
    "L'avantage de l'imputation est qu'elle fonctionne avec n'importe quel modèle de machine learning. Reproduisez l'approche de la question 3 en remplaçant le modèle linéaire par un *support vector machine* (SVM) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fAWf0La0L441",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# model <- svm(maxO3 ~ ., data = ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xu97d7PL7u8",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y1x_9zffL9UX",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "preproc <- preProcess(ozone[c(\"T9\", \"T12\", \"T15\")], method = \"medianImpute\")  # Calcul des médianes des colonnes du jeu d'entraînement\n",
    "print(preproc$median)  # Affichage des médianes calculées\n",
    "\n",
    "ozone.imputed <- predict(preproc, newdata = ozone)  # Imputation du jeu d'entraînement avec les médianes précalculées\n",
    "print(head(ozone.imputed))  # Affichage des premières lignes du jeu de données imputé\n",
    "\n",
    "model <- svm(maxO3 ~ ., data = ozone.imputed)  # Entraînement du SVM sur le jeu imputé\n",
    "print(summary(model))  # Affichage des paramètres du modèle\n",
    "\n",
    "X.new.imputed <- predict(preproc, newdata = X.new.na)  # Imputation des nouvelles données par les médianes précalculées\n",
    "print(X.new.imputed)  # Affichage des nouvelles données imputées\n",
    "\n",
    "prediction <- predict(model, newdata = X.new.imputed)  # Prédiction sur les nouvelles données imputées\n",
    "print(prediction)  # Affichage de la prédiction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A5Yfliqb_btF"
   },
   "source": [
    "## Question 6 : gradient boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sSncuDRI_bp_"
   },
   "source": [
    "En dehors du modèle linéaire, il existe une autre classe de modèles qui incorporent les valeurs manquantes de manière naturelle : les modèles à base d'arbres de décisions. Parmi eux, on peut citer :\n",
    "\n",
    "* **l'arbre de décision simple**, un modèle bien interprétable mais difficile à paramétrer et peu efficace en prédiction ;\n",
    "* **la forêt aléatoire**, un ensemble d'arbres de décision choisis aléatoirement, qui est un modèle robuste, facile à paramétrer, et très efficace en prédiction ;\n",
    "* **le boosting**, une séquence d'arbres s'affinant au fil de l'entraînement, qui est imbattable en prédiction, mais requiert plus d'expérience dans sa paramétrisation.\n",
    "\n",
    "Nous nous concentrerons ici sur le **boosting** avec la librairie `xgboost`, qui est très utilisée en pratique et est une des seules librairies à implémenter cette gestion automatique des données manquantes en R.\n",
    "\n",
    "Exécutez la cellule suivante avec chacune des 7 versions proposées de xgboost, en décommentant la ligne. Déterminez la particularité de chaque version, et son utilité. Vous pouvez vous aider de la documentation de xgboost : https://cran.r-project.org/web/packages/xgboost/xgboost.pdf#page=58\n",
    "\n",
    "Comparez également les résultats. Quelles prédictions vous semblent les plus pertinentes ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YmGbZUJ0h4v7",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "### covariates <- as.matrix(ozone[, c(\"T9\", \"T12\", \"T15\")])\n",
    "label <- ozone$maxO3\n",
    "\n",
    "# 1.\n",
    "# xgb.model <- xgboost(data = covariates, label = label, nrounds = 30, missing = NA, booster = 'gbtree', objective = \"reg:squarederror\")\n",
    "# 2.\n",
    "# xgb.model <- xgboost(data = covariates, label = label, nrounds = 60, missing = NA, booster = 'gbtree', objective = \"reg:squarederror\")\n",
    "# 3.\n",
    "# xgb.model <- xgboost(data = covariates, label = label, nrounds = 300, missing = NA, booster = 'gbtree', objective = \"reg:squarederror\", early_stopping_rounds = 5)\n",
    "# 4.\n",
    "# xgb.model <- xgboost(data = covariates, label = label, nrounds = 30, missing = 0, booster = 'gbtree', objective = \"reg:squarederror\")\n",
    "# 5.\n",
    "# xgb.model <- xgboost(data = covariates, label = label, nrounds = 30, missing = NA, booster = 'gblinear', objective = \"reg:squarederror\")\n",
    "# 6.\n",
    "# xgb.model <- xgboost(data = covariates, label = label, nrounds = 30, missing = NA, booster = 'gbtree', objective = \"reg:squaredlogerror\")\n",
    "# 7.\n",
    "# xgb.model <- xgboost(data = covariates, label = label, nrounds = 30, missing = NA, booster = 'gbtree', objective = \"reg:squarederror\", verbose = FALSE)\n",
    "\n",
    "\n",
    "prediction.xgb <- predict(xgb.model, as.matrix(X.new.na))\n",
    "print(prediction.xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oXqtcMSUPF8N",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LTOgz4G97U5V"
   },
   "source": [
    "1. La première version utilise les paramètres par défaut.\n",
    "2. `nrounds = 60` : on utilise une séquence de 60 arbres plutôt que 30, ce qui est censé améliorer la performance, mais prend deux fois plus de temps.\n",
    "3. `nrounds = 300, early_stopping_rounds = 5` : la méthode d'early stopping est très efficace pour avoir le modèle le plus performant possible sans perdre de temps. A chaque tour, on fait un test : si la performance ne s'est pas améliorée depuis 5 tours, alors on arrête. Par conséquent, on peut mettre un nombre de tours très grand, ce n'est pas grave, on s'arrêtera sûrement avant !\n",
    "4. `missing = 0` : on déclare ainsi que les valeurs manquantes sont encodées par des 0 (ou une autre valeur, -1 par exemple ou 9999) au lieu de `NA`. Selon le jeu de données qu'on utilise, ce paramètre peut être très utile !\n",
    "5. `booster = 'gblinear'` : on utilise comme modèle de base un modèle linéaire plutôt qu'un arbre de décision. A tester car ça peut être plus performant dans certains cas, notamment quand on a beaucoup de variables ou qu'on suspecte des effets linéaires.\n",
    "6. `objective = 'reg:squaredlogerror'` : on peut également changer le critère d'erreur, il y en a plusieurs possible, et il faut choisir celui qui est le plus adapté à son problème. Utiliser la *Root Mean Squared **Log** Error* (RMS**L**E), squared**log**error dans xgboost) au lieu de la plus classique *Root Mean Squared Error* (RMSE, squarederror dans xgboost) a deux intérêt : limiter l'impact des valeurs aberrantes qui ont des erreurs énormes, et pénaliser davantage les sous-estimations que les sur-estimations.\n",
    "7. `verbose = FALSE` : n'affiche pas les performances intermédiaires, pour plus de légèreté.\n",
    "\n",
    "L'objectif `'reg:squaredlogerror'` n'est clairement pas adapté ici, donnant une prédiction aberrante. Pour les autres, il est difficile d'évaluer la qualité de la prédiction puisqu'on ne connaît pas la vraie valeur, d'où l'intérêt de tester le modèle sur des \"nouvelles\" valeurs qui ne font pas partie du jeu d'entraînement, mais dont on connaît la réponse. Cette démarche de validation de modèle n'est pas détaillée ici, mais elle est essentielle dans un processus de machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "78WrTpVrPdWc"
   },
   "source": [
    "## Question 7 : et si $X_{new}$ est toujours complet ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hOxTGqnQQE0R"
   },
   "source": [
    "Est-il possible qu'il y ait des valeurs manquantes dans le jeu d'entraînement, mais jamais dans les nouvelles données ? Donnez un exemple de scénario, dans le cas des données `ozone`, puis dans votre domaine d'étude.\n",
    "\n",
    "Que faire dans ce cas ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ykobZbEBYZ-1",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "X.new <- data.frame(T9 = 15.1, T12 = 17.2, T15 = 19.7, row.names = '20250701')\n",
    "print(X.new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0XJInvaJQQM_",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-CCPVuqoayj"
   },
   "source": [
    "On peut tout à fait concevoir que les nouvelles valeurs de température n'aient jamais de valeurs manquantes. Cela peut être parce que les capteurs de température ont été changés après l'étude pour des versions plus robustes, ou parce que la connexion internet a été améliorée, par exemple.\n",
    "\n",
    "Bien sûr, tout ce qu'on a vu avec $X_{new}$ incomplet peut s'appliquer dans ce cas plus facile, et heureusement (on n'est jamais obligé d'avoir des valeurs manquantes !).\n",
    "\n",
    "Cependant, si on est certain qu'il n'y aura plus jamais de valeurs manquantes, alors il vaut mieux ne pas s'entraîner avec des valeurs manquantes pour ne pas introduire de biais. En particulier, les méthodes à base d'arbres de décision risquent de trop s'appuyer sur la présence de `NA`, et donner de fausses prédictions. Il est donc recommandé de faire une **imputation** avant d'entraîner le modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FcCRoS5LOUup"
   },
   "source": [
    "## Conclusion pour la prédiction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4ujlkaMGkyS"
   },
   "source": [
    "Retenons trois informations importantes:\n",
    "* La seule manière de gérer les valeurs manquantes en entraînement et en prédiction pour n'importe quel modèle de machine learning est de faire d'abord une **imputation**.\n",
    "* Imputer le jeu d'entraînement est aussi la méthode la plus souvent adaptée si on sait qu'on n'aura pas de données manquantes en prédiction.\n",
    "* Au cas par cas, certains modèles ont des implémentations qui permettent de gérer nativement les valeurs manquantes sans faire d'imputation, et d'optimiser ainsi les performances. C'est le cas du modèle linéaire, et des modèles à base d'arbres de décision comme le gradient boosting."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "srD83mCEhilw",
    "ddd8fX056r0w",
    "EjMXsTCwXzSL",
    "poRONxWW7kSb",
    "idfeWJH2-1bp",
    "RueUgT8E9yVF",
    "1r8-iRh_JO3a",
    "ySkP9POZK8JS",
    "IFuvjqP7-x7-",
    "2xu97d7PL7u8",
    "oXqtcMSUPF8N",
    "0XJInvaJQQM_"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
